{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Naive Bayes Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parth7/ML-for-finance/blob/main/Naive_Bayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVJT9tfGZK-f"
      },
      "source": [
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "from csv import reader\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDrjQWKDZK-h"
      },
      "source": [
        "file = pd.read_excel('cummulative_data_complete.xlsx') \n",
        "file = file.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSnECMF3ZK-h",
        "outputId": "5963db00-cce6-4100-e103-dba404d5c6e9"
      },
      "source": [
        "print(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13.992114  1.      ]\n",
            " [13.930585  1.      ]\n",
            " [13.809978  1.      ]\n",
            " ...\n",
            " [32.04817  46.      ]\n",
            " [31.49364  46.      ]\n",
            " [31.84174  46.      ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-1gUZvgZK-i",
        "outputId": "ab0c4572-c304-40d0-865f-5d41d3526432"
      },
      "source": [
        "#### DOESN'T WORK ON OUR DATASET\n",
        "### Source: https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
        "\n",
        "from csv import reader\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "from math import exp\n",
        "from math import pi\n",
        " \n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        " \n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor _ in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        " \n",
        "# Split the dataset by class values, returns a dictionary\n",
        "def separate_by_class(dataset):\n",
        "\tseparated = dict()\n",
        "\tfor i in range(len(dataset)):\n",
        "\t\tvector = dataset[i]\n",
        "\t\tclass_value = vector[-1]\n",
        "\t\tif (class_value not in separated):\n",
        "\t\t\tseparated[class_value] = list()\n",
        "\t\tseparated[class_value].append(vector)\n",
        "\treturn separated\n",
        " \n",
        "# Calculate the mean of a list of numbers\n",
        "def mean(numbers):\n",
        "\treturn sum(numbers)/float(len(numbers))\n",
        " \n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def stdev(numbers):\n",
        "\tavg = mean(numbers)\n",
        "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
        "\treturn sqrt(variance)\n",
        " \n",
        "# Calculate the mean, stdev and count for each column in a dataset\n",
        "def summarize_dataset(dataset):\n",
        "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
        "\tdel(summaries[-1])\n",
        "\treturn summaries\n",
        " \n",
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "\tseparated = separate_by_class(dataset)\n",
        "\tsummaries = dict()\n",
        "\tfor class_value, rows in separated.items():\n",
        "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
        "\treturn summaries\n",
        " \n",
        "# Calculate the Gaussian probability distribution function for x\n",
        "def calculate_probability(x, mean, stdev):\n",
        "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
        " \n",
        "# Calculate the probabilities of predicting each class for a given row\n",
        "def calculate_class_probabilities(summaries, row):\n",
        "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
        "\tprobabilities = dict()\n",
        "\tfor class_value, class_summaries in summaries.items():\n",
        "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
        "\t\tfor i in range(len(class_summaries)):\n",
        "\t\t\tmean, stdev, _ = class_summaries[i]\n",
        "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
        "\treturn probabilities\n",
        " \n",
        "# Predict the class for a given row\n",
        "def predict(summaries, row):\n",
        "\tprobabilities = calculate_class_probabilities(summaries, row)\n",
        "\tbest_label, best_prob = None, -1\n",
        "\tfor class_value, probability in probabilities.items():\n",
        "\t\tif best_label is None or probability > best_prob:\n",
        "\t\t\tbest_prob = probability\n",
        "\t\t\tbest_label = class_value\n",
        "\treturn best_label\n",
        " \n",
        "# Naive Bayes Algorithm\n",
        "def naive_bayes(train, test):\n",
        "\tsummarize = summarize_by_class(train)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\toutput = predict(summarize, row)\n",
        "\t\tpredictions.append(output)\n",
        "\treturn(predictions)\n",
        " \n",
        "# Test Naive Bayes on Iris Dataset\n",
        "seed(1)\n",
        "filename = 'iris.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 93.33333333333333]\n",
            "Mean Accuracy: 95.333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhK1EY9rZK-j",
        "outputId": "d44c0f68-2149-4374-e07e-bbe231eb2f1f"
      },
      "source": [
        "#### DOESN'T WORK ON OUR DATASET\n",
        "### Source: https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
        "\n",
        "from math import sqrt\n",
        "from math import pi\n",
        "from math import exp\n",
        " \n",
        "# Split the dataset by class values, returns a dictionary\n",
        "def separate_by_class(dataset):\n",
        "\tseparated = dict()\n",
        "\tfor i in range(len(dataset)):\n",
        "\t\tvector = dataset[i]\n",
        "\t\tclass_value = vector[-1]\n",
        "\t\tif (class_value not in separated):\n",
        "\t\t\tseparated[class_value] = list()\n",
        "\t\tseparated[class_value].append(vector)\n",
        "\treturn separated\n",
        " \n",
        "# Calculate the mean of a list of numbers\n",
        "def mean(numbers):\n",
        "\treturn sum(numbers)/float(len(numbers))\n",
        " \n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def stdev(numbers):\n",
        "\tavg = mean(numbers)\n",
        "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
        "\treturn sqrt(variance)\n",
        " \n",
        "# Calculate the mean, stdev and count for each column in a dataset\n",
        "def summarize_dataset(dataset):\n",
        "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
        "\tdel(summaries[-1])\n",
        "\treturn summaries\n",
        " \n",
        "# Split dataset by class then calculate statistics for each row\n",
        "def summarize_by_class(dataset):\n",
        "\tseparated = separate_by_class(dataset)\n",
        "\tsummaries = dict()\n",
        "\tfor class_value, rows in separated.items():\n",
        "\t\tsummaries[class_value] = summarize_dataset(rows)\n",
        "\treturn summaries\n",
        " \n",
        "# Calculate the Gaussian probability distribution function for x\n",
        "def calculate_probability(x, mean, stdev):\n",
        "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
        " \n",
        "# Calculate the probabilities of predicting each class for a given row\n",
        "def calculate_class_probabilities(summaries, row):\n",
        "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\n",
        "\tprobabilities = dict()\n",
        "\tfor class_value, class_summaries in summaries.items():\n",
        "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
        "\t\tfor i in range(len(class_summaries)):\n",
        "\t\t\tmean, stdev, _ = class_summaries[i]\n",
        "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
        "\treturn probabilities\n",
        " \n",
        "# Test calculating class probabilities\n",
        "dataset = [[3.393533211,2.331273381,0],\n",
        "\t[3.110073483,1.781539638,0],\n",
        "\t[1.343808831,3.368360954,0],\n",
        "\t[3.582294042,4.67917911,0],\n",
        "\t[2.280362439,2.866990263,0],\n",
        "\t[7.423436942,4.696522875,1],\n",
        "\t[5.745051997,3.533989803,1],\n",
        "\t[9.172168622,2.511101045,1],\n",
        "\t[7.792783481,3.424088941,1],\n",
        "\t[7.939820817,0.791637231,1]]\n",
        "summaries = summarize_by_class(dataset)\n",
        "probabilities = calculate_class_probabilities(summaries, dataset[0])\n",
        "print(probabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.05032427673372076, 1: 0.00011557718379945765}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hjaOORoZK-k",
        "outputId": "67a89c9c-77d6-4d57-d9d7-674c772b8708"
      },
      "source": [
        "#### DOESN'T WORK ON OUR DATASET\n",
        "### Source: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "\n",
        ">>> from sklearn.datasets import load_iris\n",
        ">>> from sklearn.model_selection import train_test_split\n",
        ">>> from sklearn.naive_bayes import GaussianNB\n",
        ">>> X, y = load_iris(return_X_y=True)\n",
        ">>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        ">>> gnb = GaussianNB()\n",
        ">>> y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        ">>> print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        "...       % (X_test.shape[0], (y_test != y_pred).sum()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 5000 points : 24501665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Elektrolux\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayoDY9thZK-l"
      },
      "source": [
        "#### WORKS ON OUR DATASET\n",
        "### Source: https://www.analyticsvidhya.com/blog/2021/01/a-guide-to-the-naive-bayes-algorithm/\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_excel('cummulative_data_complete.xlsx') \n",
        "X = dataset.iloc[:, [0]].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Training the Naive Bayes model on the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "ac = accuracy_score(y_test,y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dDSTn_GZK-l",
        "outputId": "9acd1f4c-dbc2-469b-9db5-9f3ac05a458a"
      },
      "source": [
        "print(ac)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4WTEpt9ZK-m",
        "outputId": "3fbb068a-9348-4f83-eea4-66aadc00b65a"
      },
      "source": [
        "#### WORKS ON OUR DATASET\n",
        "### Source: https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
        "\n",
        "dataset = pd.read_excel('cummulative_data_complete.xlsx') \n",
        "X = dataset.iloc[:, [0]].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109)\n",
        "\n",
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#Train the model using the training sets\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZIG1saNZK-m",
        "outputId": "83783db3-7322-4ea7-f241-857ef6b1a80f"
      },
      "source": [
        "#### WORKS ON OUR DATASET\n",
        "### Source: https://www.geeksforgeeks.org/naive-bayes-classifiers/\n",
        "\n",
        "dataset = pd.read_excel('cummulative_data_complete.xlsx') \n",
        "X = dataset.iloc[:, [0]].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# splitting X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "  \n",
        "# training the model on training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "  \n",
        "# making predictions on the testing set\n",
        "y_pred = gnb.predict(X_test)\n",
        "  \n",
        "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
        "from sklearn import metrics\n",
        "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gaussian Naive Bayes model accuracy(in %): 53.425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft9c1qIsZK-n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}