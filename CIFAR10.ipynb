{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgggDteudFuFH4+e/GwoGC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22f1543332fa4b27b23ecea610da3b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_314348eff48a49b3886f028a1b8b5a0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8c70225d1f846019a7ebe57b0e33d88",
              "IPY_MODEL_11030024ff6f450c80b1798b6beaeb82"
            ]
          }
        },
        "314348eff48a49b3886f028a1b8b5a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8c70225d1f846019a7ebe57b0e33d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a4c706f08ce4ca5b68961a9863e9cc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d04134a434a4498e914ae503c8a2aa9a"
          }
        },
        "11030024ff6f450c80b1798b6beaeb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9626147266e47389b89abf9073fb7ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:07&lt;00:00, 23149585.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42e5d9aee0fb48d09b5c2d0bb90fdda1"
          }
        },
        "4a4c706f08ce4ca5b68961a9863e9cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d04134a434a4498e914ae503c8a2aa9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9626147266e47389b89abf9073fb7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42e5d9aee0fb48d09b5c2d0bb90fdda1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parth7/ML-for-finance/blob/main/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFKcMhlMdAqM"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1tE_n2Oefbe",
        "outputId": "437fc085-cfa0-49ad-edbd-75e3e11f6886"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwASokpfnk8t"
      },
      "source": [
        "import numpy as np\n",
        "import torch as th"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRJrIFv5uIUq"
      },
      "source": [
        "ones = th.ones(3, 2)\n",
        "zeros_3d_tensor = th.zeros(3, 2, 2)\n",
        "zeros_1d_array = zeros_3d_tensor.view(3 * 2 * 2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J813TT_uMDy",
        "outputId": "d266a872-fad6-4217-a9d9-cd6a37cc09f8"
      },
      "source": [
        "zeros_3d_tensor = th.zeros(3, 2, 2)\n",
        "print(\"Original size:\", zeros_3d_tensor.size())\n",
        "\n",
        "zeros_1d_array = zeros_3d_tensor.view(3 * 2 * 2)\n",
        "print(\"Reshaped tensor:\", zeros_1d_array.size())\n",
        "\n",
        "zeros_2d_matrix = zeros_3d_tensor.view(-1, 2 * 2)\n",
        "\n",
        "print(\"Matrix shape:\", zeros_2d_matrix.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original size: torch.Size([3, 2, 2])\n",
            "Reshaped tensor: torch.Size([12])\n",
            "Matrix shape: torch.Size([3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1mQc8fmvGzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ccda58-46c5-47b3-bc23-84925d4bb5e4"
      },
      "source": [
        "2 * ones + 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.],\n",
              "        [3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEQD1i-fUqv0",
        "outputId": "ae4c602a-aa88-4035-d6d8-14623d252b97"
      },
      "source": [
        "ones[:,1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRIgbojwUxs9"
      },
      "source": [
        "ones_matrix = np.ones((2, 2), dtype=np.float32)\n",
        "ones_tensor = th.from_numpy(ones_matrix)\n",
        "numpy_matrix = ones_tensor.numpy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Wcy8qiU7KC",
        "outputId": "78bb222e-4f7e-439b-8379-403d1a31e2e3"
      },
      "source": [
        "ones_tensor = th.ones( (2,2), requires_grad=True)\n",
        "print(ones_tensor)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUacnbhIV9WT",
        "outputId": "a2fb568e-e1bd-467a-b1b1-42972c818c6e"
      },
      "source": [
        "x = th.ones(1, requires_grad=True)\n",
        "a = 2\n",
        "b = 5\n",
        "y = a*x + b \n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([7.], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYxRtOQyWHfr",
        "outputId": "564c0342-483c-46bc-b9f5-e2cd749b6099"
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abpQ5A9qhQhG"
      },
      "source": [
        "import time as time"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOCGAQavWd_3",
        "outputId": "be8b9f32-a877-4d3b-b552-c80231eb3ff5"
      },
      "source": [
        "if th.cuda.is_available():\n",
        "  # Create tensors\n",
        "  x = th.ones(1000, 1000)\n",
        "  y = 2 * x + 3\n",
        "  # Do the calculation on cpu (default)\n",
        "  start_time = time.time()\n",
        "  # Matrix multiplication (for benchmark purpose)\n",
        "  results = th.mm(x, y)\n",
        "  time_cpu = time.time() - start_time\n",
        "  \n",
        "  # Do the same calculation but on the gpu\n",
        "  # First move tensors to gpu\n",
        "  x = x.to(\"cuda\")\n",
        "  y = y.to(\"cuda\")\n",
        "  start_time = time.time()\n",
        "  # Matrix multiplication (for benchmark purpose)\n",
        "  results = th.mm(x, y)\n",
        "  time_gpu = time.time() - start_time\n",
        "  \n",
        "  print(\"Time on CPU: {:.5f}s \\t Time on GPU: {:.5f}s\".format(time_cpu, time_gpu))\n",
        "  print(\"Speed up: Computation was {:.0f}X faster on GPU!\".format(time_cpu / time_gpu))\n",
        "  \n",
        "else:\n",
        "  print(\"You need to enable GPU accelaration in colab (runtime->change runtime type)\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time on CPU: 0.04809s \t Time on GPU: 0.00730s\n",
            "Speed up: Computation was 7X faster on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5nJ_U7HgAFc"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXZkivRwkD7J"
      },
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if th.cuda.is_available():\n",
        "  th.backends.cudnn.deterministic = True\n",
        "  th.cuda.manual_seed(seed)\n",
        "\n",
        "# Define default device, we should use the GPU (cuda) if available\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFn4mUj_mHpM"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "n_training_samples = 20000 # Max: 50 000 - n_val_samples\n",
        "n_val_samples = 5000\n",
        "n_test_samples = 5000\n",
        "\n",
        "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
        "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "22f1543332fa4b27b23ecea610da3b01",
            "314348eff48a49b3886f028a1b8b5a0f",
            "b8c70225d1f846019a7ebe57b0e33d88",
            "11030024ff6f450c80b1798b6beaeb82",
            "4a4c706f08ce4ca5b68961a9863e9cc5",
            "d04134a434a4498e914ae503c8a2aa9a",
            "a9626147266e47389b89abf9073fb7ff",
            "42e5d9aee0fb48d09b5c2d0bb90fdda1"
          ]
        },
        "id": "ahPYWL0Nmtbo",
        "outputId": "87c63fcb-d351-4e8f-fe3f-babb06bb40b5"
      },
      "source": [
        "num_workers = 2\n",
        "test_batch_size = 4\n",
        "\n",
        "transform = transforms.Compose( [transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=test_batch_size, sampler=train_sampler,num_workers=num_workers)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, sampler=test_sampler, num_workers=num_workers)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22f1543332fa4b27b23ecea610da3b01",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv1aG2IUnyAy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsMa3MOKqmJ-"
      },
      "source": [
        "class SimpleConvolutionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleConvolutionalNetwork, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        # cf comments in forward() to have step by step comments\n",
        "        # on the shape (how we pass from a 3x32x32 input image to a 18x16x16 volume)\n",
        "        self.fc1 = nn.Linear(18 * 16 * 16, 64) \n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass,\n",
        "        x shape is (batch_size, 3, 32, 32)\n",
        "        (color channel first)\n",
        "        in the comments, we omit the batch_size in the shape\n",
        "        \"\"\"\n",
        "        # shape : 3x32x32 -> 18x32x32\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # 18x32x32 -> 18x16x16\n",
        "        x = self.pool(x)\n",
        "        # 18x16x16 -> 4608\n",
        "        x = x.view(-1, 18 * 16 * 16)\n",
        "        # 4608 -> 64\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 64 -> 10\n",
        "        # The softmax non-linearity is applied later (cf createLossAndOptimizer() fn)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLMU0oVbVBd0"
      },
      "source": [
        "class LinearClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear Classifier\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(32 * 32 * 3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten input 3x32x32 -> 3072\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.linear(x)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfsjUcuOVOA3"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    # it combines softmax with negative log likelihood loss\n",
        "    criterion = nn.CrossEntropyLoss()  \n",
        "    #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    return criterion, optimizer"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd14Fi-apyV3"
      },
      "source": [
        "def get_train_loader(batch_size):\n",
        "    return torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler,\n",
        "                                              num_workers=num_workers)\n",
        "\n",
        "# Use larger batch size for validation to speed up computation\n",
        "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler,\n",
        "                                          num_workers=num_workers)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YcnlMEYp-Ur"
      },
      "source": [
        "def train(net, batch_size, n_epochs, learning_rate):\n",
        "    \"\"\"\n",
        "    Train a neural network and print statistics of the training\n",
        "    \n",
        "    :param net: (PyTorch Neural Network)\n",
        "    :param batch_size: (int)\n",
        "    :param n_epochs: (int)  Number of iterations on the training set\n",
        "    :param learning_rate: (float) learning rate used by the optimizer\n",
        "    \"\"\"\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"n_epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate) #change in weights \n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    n_minibatches = len(train_loader)\n",
        "\n",
        "    criterion, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    # Init variables used for plotting the loss\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "    best_error = np.inf\n",
        "    best_model_path = \"best_model.pth\"\n",
        "    \n",
        "    # Move model to gpu if possible\n",
        "    net = net.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        print_every = n_minibatches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Move tensors to correct device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # print every 10th of epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:    \n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                      epoch + 1, int(100 * (i + 1) / n_minibatches), running_loss / print_every,\n",
        "                      time.time() - start_time))\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "\n",
        "        train_history.append(total_train_loss / len(train_loader))\n",
        "\n",
        "        total_val_loss = 0\n",
        "        # Do a pass on the validation set\n",
        "        # We don't need to compute gradient,\n",
        "        # we save memory and computation using th.no_grad()\n",
        "        with th.no_grad():\n",
        "          for inputs, labels in val_loader:\n",
        "              # Move tensors to correct device\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              # Forward pass\n",
        "              predictions = net(inputs)\n",
        "              val_loss = criterion(predictions, labels)\n",
        "              total_val_loss += val_loss.item()\n",
        "            \n",
        "        val_history.append(total_val_loss / len(val_loader))\n",
        "        # Save model that performs best on validation set\n",
        "        if total_val_loss < best_error:\n",
        "            best_error = total_val_loss\n",
        "            th.save(net.state_dict(), best_model_path)\n",
        "\n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "\n",
        "    print(\"Training Finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
        "    \n",
        "    # Load best model\n",
        "    net.load_state_dict(th.load(best_model_path))\n",
        "    \n",
        "    return train_history, val_history"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIh0xPO8qNxR",
        "outputId": "b206d5bd-7ea2-40b3-ecbb-d2e5685bcd50"
      },
      "source": [
        "net = SimpleConvolutionalNetwork()\n",
        "\n",
        "train_history, val_history = train(net, batch_size=32, n_epochs=10, learning_rate=0.001)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 32\n",
            "n_epochs= 10\n",
            "learning_rate= 0.001\n",
            "==============================\n",
            "Epoch 1, 10% \t train_loss: 2.05 took: 0.74s\n",
            "Epoch 1, 20% \t train_loss: 1.86 took: 0.47s\n",
            "Epoch 1, 30% \t train_loss: 1.79 took: 0.47s\n",
            "Epoch 1, 40% \t train_loss: 1.70 took: 0.44s\n",
            "Epoch 1, 50% \t train_loss: 1.63 took: 0.46s\n",
            "Epoch 1, 60% \t train_loss: 1.58 took: 0.46s\n",
            "Epoch 1, 70% \t train_loss: 1.51 took: 0.46s\n",
            "Epoch 1, 80% \t train_loss: 1.47 took: 0.47s\n",
            "Epoch 1, 90% \t train_loss: 1.47 took: 0.45s\n",
            "Validation loss = 1.34\n",
            "Epoch 2, 10% \t train_loss: 1.40 took: 0.54s\n",
            "Epoch 2, 20% \t train_loss: 1.41 took: 0.46s\n",
            "Epoch 2, 30% \t train_loss: 1.31 took: 0.45s\n",
            "Epoch 2, 40% \t train_loss: 1.32 took: 0.46s\n",
            "Epoch 2, 50% \t train_loss: 1.35 took: 0.45s\n",
            "Epoch 2, 60% \t train_loss: 1.30 took: 0.47s\n",
            "Epoch 2, 70% \t train_loss: 1.29 took: 0.46s\n",
            "Epoch 2, 80% \t train_loss: 1.23 took: 0.46s\n",
            "Epoch 2, 90% \t train_loss: 1.31 took: 0.46s\n",
            "Validation loss = 1.28\n",
            "Epoch 3, 10% \t train_loss: 1.20 took: 0.55s\n",
            "Epoch 3, 20% \t train_loss: 1.17 took: 0.44s\n",
            "Epoch 3, 30% \t train_loss: 1.24 took: 0.45s\n",
            "Epoch 3, 40% \t train_loss: 1.23 took: 0.47s\n",
            "Epoch 3, 50% \t train_loss: 1.18 took: 0.45s\n",
            "Epoch 3, 60% \t train_loss: 1.18 took: 0.45s\n",
            "Epoch 3, 70% \t train_loss: 1.19 took: 0.47s\n",
            "Epoch 3, 80% \t train_loss: 1.18 took: 0.44s\n",
            "Epoch 3, 90% \t train_loss: 1.21 took: 0.46s\n",
            "Validation loss = 1.27\n",
            "Epoch 4, 10% \t train_loss: 1.11 took: 0.61s\n",
            "Epoch 4, 20% \t train_loss: 1.07 took: 0.44s\n",
            "Epoch 4, 30% \t train_loss: 1.09 took: 0.46s\n",
            "Epoch 4, 40% \t train_loss: 1.08 took: 0.46s\n",
            "Epoch 4, 50% \t train_loss: 1.13 took: 0.45s\n",
            "Epoch 4, 60% \t train_loss: 1.09 took: 0.45s\n",
            "Epoch 4, 70% \t train_loss: 1.14 took: 0.44s\n",
            "Epoch 4, 80% \t train_loss: 1.10 took: 0.47s\n",
            "Epoch 4, 90% \t train_loss: 1.06 took: 0.45s\n",
            "Validation loss = 1.20\n",
            "Epoch 5, 10% \t train_loss: 0.92 took: 0.56s\n",
            "Epoch 5, 20% \t train_loss: 1.00 took: 0.43s\n",
            "Epoch 5, 30% \t train_loss: 0.97 took: 0.45s\n",
            "Epoch 5, 40% \t train_loss: 1.01 took: 0.46s\n",
            "Epoch 5, 50% \t train_loss: 1.00 took: 0.45s\n",
            "Epoch 5, 60% \t train_loss: 1.05 took: 0.45s\n",
            "Epoch 5, 70% \t train_loss: 1.01 took: 0.45s\n",
            "Epoch 5, 80% \t train_loss: 1.02 took: 0.47s\n",
            "Epoch 5, 90% \t train_loss: 1.02 took: 0.47s\n",
            "Validation loss = 1.20\n",
            "Epoch 6, 10% \t train_loss: 0.92 took: 0.54s\n",
            "Epoch 6, 20% \t train_loss: 0.94 took: 0.45s\n",
            "Epoch 6, 30% \t train_loss: 0.91 took: 0.45s\n",
            "Epoch 6, 40% \t train_loss: 0.92 took: 0.45s\n",
            "Epoch 6, 50% \t train_loss: 0.89 took: 0.44s\n",
            "Epoch 6, 60% \t train_loss: 0.93 took: 0.46s\n",
            "Epoch 6, 70% \t train_loss: 0.95 took: 0.46s\n",
            "Epoch 6, 80% \t train_loss: 0.94 took: 0.44s\n",
            "Epoch 6, 90% \t train_loss: 0.95 took: 0.48s\n",
            "Validation loss = 1.18\n",
            "Epoch 7, 10% \t train_loss: 0.84 took: 0.55s\n",
            "Epoch 7, 20% \t train_loss: 0.82 took: 0.44s\n",
            "Epoch 7, 30% \t train_loss: 0.84 took: 0.45s\n",
            "Epoch 7, 40% \t train_loss: 0.84 took: 0.43s\n",
            "Epoch 7, 50% \t train_loss: 0.88 took: 0.46s\n",
            "Epoch 7, 60% \t train_loss: 0.88 took: 0.47s\n",
            "Epoch 7, 70% \t train_loss: 0.82 took: 0.44s\n",
            "Epoch 7, 80% \t train_loss: 0.85 took: 0.45s\n",
            "Epoch 7, 90% \t train_loss: 0.89 took: 0.45s\n",
            "Validation loss = 1.18\n",
            "Epoch 8, 10% \t train_loss: 0.73 took: 0.62s\n",
            "Epoch 8, 20% \t train_loss: 0.78 took: 0.45s\n",
            "Epoch 8, 30% \t train_loss: 0.77 took: 0.44s\n",
            "Epoch 8, 40% \t train_loss: 0.78 took: 0.48s\n",
            "Epoch 8, 50% \t train_loss: 0.83 took: 0.45s\n",
            "Epoch 8, 60% \t train_loss: 0.80 took: 0.46s\n",
            "Epoch 8, 70% \t train_loss: 0.81 took: 0.47s\n",
            "Epoch 8, 80% \t train_loss: 0.81 took: 0.47s\n",
            "Epoch 8, 90% \t train_loss: 0.80 took: 0.46s\n",
            "Validation loss = 1.24\n",
            "Epoch 9, 10% \t train_loss: 0.70 took: 0.54s\n",
            "Epoch 9, 20% \t train_loss: 0.70 took: 0.45s\n",
            "Epoch 9, 30% \t train_loss: 0.70 took: 0.45s\n",
            "Epoch 9, 40% \t train_loss: 0.75 took: 0.45s\n",
            "Epoch 9, 50% \t train_loss: 0.79 took: 0.45s\n",
            "Epoch 9, 60% \t train_loss: 0.71 took: 0.46s\n",
            "Epoch 9, 70% \t train_loss: 0.75 took: 0.45s\n",
            "Epoch 9, 80% \t train_loss: 0.72 took: 0.47s\n",
            "Epoch 9, 90% \t train_loss: 0.79 took: 0.44s\n",
            "Validation loss = 1.24\n",
            "Epoch 10, 10% \t train_loss: 0.64 took: 0.54s\n",
            "Epoch 10, 20% \t train_loss: 0.62 took: 0.45s\n",
            "Epoch 10, 30% \t train_loss: 0.66 took: 0.45s\n",
            "Epoch 10, 40% \t train_loss: 0.67 took: 0.46s\n",
            "Epoch 10, 50% \t train_loss: 0.68 took: 0.46s\n",
            "Epoch 10, 60% \t train_loss: 0.69 took: 0.44s\n",
            "Epoch 10, 70% \t train_loss: 0.70 took: 0.48s\n",
            "Epoch 10, 80% \t train_loss: 0.70 took: 0.46s\n",
            "Epoch 10, 90% \t train_loss: 0.70 took: 0.47s\n",
            "Validation loss = 1.25\n",
            "Training Finished, took 55.35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opC5lSCiqztw",
        "outputId": "86e3241b-589e-46f3-cfe9-06201050fe1f"
      },
      "source": [
        "outputs = net(images.to(device))\n",
        "print(outputs.size())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsoCl_yoAmJF",
        "outputId": "16125531-7bb9-48a8-b814-4c556dafab22"
      },
      "source": [
        "def dataset_accuracy(net, data_loader, name=\"\"):\n",
        "    net = net.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "    accuracy = 100 * float(correct) / total\n",
        "    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\n",
        "\n",
        "def train_set_accuracy(net):\n",
        "    dataset_accuracy(net, train_loader, \"train\")\n",
        "\n",
        "def val_set_accuracy(net):\n",
        "    dataset_accuracy(net, val_loader, \"validation\")  \n",
        "    \n",
        "def test_set_accuracy(net):\n",
        "    dataset_accuracy(net, test_loader, \"test\")\n",
        "\n",
        "def compute_accuracy(net):\n",
        "    train_set_accuracy(net)\n",
        "    val_set_accuracy(net)\n",
        "    test_set_accuracy(net)\n",
        "    \n",
        "print(\"Computing accuracy...\")\n",
        "compute_accuracy(net)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing accuracy...\n",
            "Accuracy of the network on the 20000 train images: 75.09 %\n",
            "Accuracy of the network on the 5000 validation images: 59.28 %\n",
            "Accuracy of the network on the 5000 test images: 59.94 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YG8kn-dAo49",
        "outputId": "c0fa2e2f-4e3a-49c3-b235-e027ac73b0df"
      },
      "source": [
        "def accuracy_per_class(net):\n",
        "    net = net.to(device)\n",
        "    n_classes = 10\n",
        "    # (real, predicted)\n",
        "    confusion_matrix = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        for i in range(test_batch_size):\n",
        "            confusion_matrix[labels[i], predicted[i]] += 1\n",
        "            label = labels[i]\n",
        "\n",
        "    print(\"{:<10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\n",
        "    for i in range(n_classes):\n",
        "        class_total = confusion_matrix[i, :].sum()\n",
        "        class_correct = confusion_matrix[i, i]\n",
        "        percentage_correct = 100.0 * float(class_correct) / class_total\n",
        "        \n",
        "        print('{:<10} {:^10.2f}'.format(classes[i], percentage_correct))\n",
        "    return confusion_matrix\n",
        "\n",
        "confusion_matrix = accuracy_per_class(net)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class      Accuracy (%)\n",
            "plane        69.88   \n",
            "car          74.46   \n",
            "bird         45.90   \n",
            "cat          41.05   \n",
            "deer         59.96   \n",
            "dog          47.13   \n",
            "frog         71.08   \n",
            "horse        64.44   \n",
            "ship         68.45   \n",
            "truck        57.31   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDmjKJjBBnV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}